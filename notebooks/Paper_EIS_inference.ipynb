{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#SoC Classification Inference"
      ],
      "metadata": {
        "id": "sDj4d4E60qRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preventing disconnect from Google Colab notebook:\n",
        "Right-click on the connect button and paste the code to the console of the UI:\n",
        "\n",
        "\n",
        "```\n",
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\");\n",
        "    document.querySelector(\"colab-connect-button\").click() \n",
        " }\n",
        " setInterval(ClickConnect,60000)\n",
        "```"
      ],
      "metadata": {
        "id": "YyZY94ASp0yA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "AWqyY0_VS7jB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7ZBai_6xa0I",
        "outputId": "75f9952d-f1be-4acc-df2f-74cf325984ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 189 kB 14.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.9 MB/s \n",
            "\u001b[?25habsl-py==1.0.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.2.0\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==21.3.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "arviz==0.11.4\n",
            "astor==0.8.1\n",
            "astropy==4.3.1\n",
            "astunparse==1.6.3\n",
            "atari-py==0.2.9\n",
            "atomicwrites==1.4.0\n",
            "attrs==21.4.0\n",
            "audioread==2.1.9\n",
            "autograd==1.3\n",
            "Babel==2.9.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==4.1.0\n",
            "blis==0.4.1\n",
            "bokeh==2.3.3\n",
            "Bottleneck==1.3.4\n",
            "branca==0.4.2\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.10\n",
            "cached-property==1.5.2\n",
            "cachetools==4.2.4\n",
            "catalogue==1.0.0\n",
            "certifi==2021.10.8\n",
            "cffi==1.15.0\n",
            "cftime==1.6.0\n",
            "chardet==3.0.4\n",
            "charset-normalizer==2.0.12\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorcet==3.0.0\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.4.0\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda111==9.4.0\n",
            "cvxopt==1.2.7\n",
            "cvxpy==1.0.31\n",
            "cycler==0.11.0\n",
            "cymem==2.0.6\n",
            "Cython==0.29.28\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.4\n",
            "distributed==1.25.3\n",
            "dlib @ file:///dlib-19.18.0-cp37-cp37m-linux_x86_64.whl\n",
            "dm-tree==0.1.6\n",
            "docopt==0.6.2\n",
            "docutils==0.17.1\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.303\n",
            "easydict==1.9\n",
            "ecos==2.0.10\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\n",
            "entrypoints==0.4\n",
            "ephem==4.1.3\n",
            "et-xmlfile==1.1.0\n",
            "fa2==0.3.5\n",
            "fastai==2.5.3\n",
            "fastcore==1.3.29\n",
            "fastdownload==0.0.5\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.2\n",
            "fastrlock==0.8\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.6.0\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.4\n",
            "flatbuffers==2.0\n",
            "folium==0.8.3\n",
            "future==0.16.0\n",
            "gast==0.5.3\n",
            "GDAL==2.2.2\n",
            "gdown==4.2.2\n",
            "gensim==3.6.0\n",
            "geographiclib==1.52\n",
            "geopy==1.17.0\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.26.3\n",
            "google-api-python-client==1.12.11\n",
            "google-auth==1.35.0\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.6\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.56.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.1.2\n",
            "grpcio==1.44.0\n",
            "gspread==3.4.2\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.17.3\n",
            "h5py==3.1.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.2.3\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.14.8\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "imageio==2.4.1\n",
            "imagesize==1.3.0\n",
            "imbalanced-learn==0.8.1\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==4.11.3\n",
            "importlib-resources==5.4.0\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "intel-openmp==2022.0.2\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.7.0\n",
            "itsdangerous==1.1.0\n",
            "jax==0.3.4\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.2+cuda11.cudnn805-cp37-none-manylinux2010_x86_64.whl\n",
            "jedi==0.18.1\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "joblib==1.1.0\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==4.3.3\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.9.2\n",
            "jupyterlab-pygments==0.1.2\n",
            "jupyterlab-widgets==1.1.0\n",
            "kaggle==1.5.12\n",
            "kapre==0.3.7\n",
            "keras==2.8.0\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.4.0\n",
            "korean-lunar-calendar==0.2.1\n",
            "libclang==13.0.0\n",
            "librosa==0.8.1\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.6\n",
            "MarkupSafe==2.0.1\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.3\n",
            "matplotlib-venn==0.11.6\n",
            "missingno==0.5.1\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.12.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.3\n",
            "multiprocess==0.70.12.2\n",
            "multitasking==0.0.10\n",
            "murmurhash==1.0.6\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.13\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.2.0\n",
            "nest-asyncio==1.5.4\n",
            "netCDF4==1.5.8\n",
            "networkx==2.6.3\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "numba==0.51.2\n",
            "numexpr==2.8.1\n",
            "numpy==1.21.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.0\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==3.0.9\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "packaging==21.3\n",
            "palettable==3.3.0\n",
            "pandas==1.3.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.5.0\n",
            "panel==0.12.1\n",
            "param==1.12.0\n",
            "parso==0.8.3\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.2\n",
            "pep517==0.12.0\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==6.2.0\n",
            "plac==1.1.3\n",
            "plotly==5.5.0\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.6.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.6\n",
            "prettytable==3.2.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.13.1\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.17.3\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.11.0\n",
            "pyarrow==6.0.1\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.4\n",
            "pycparser==2.21\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.4.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==2.0.0.1\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.11.4\n",
            "PyMeeus==0.5.11\n",
            "pymongo==4.0.2\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.6\n",
            "pyparsing==3.0.7\n",
            "pyrsistent==0.18.1\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==6.1.1\n",
            "python-utils==3.1.0\n",
            "pytz==2018.9\n",
            "pyviz-comms==2.1.0\n",
            "PyWavelets==1.3.0\n",
            "PyYAML==3.13\n",
            "pyzmq==22.3.0\n",
            "qdldl==0.1.5.post0\n",
            "qtconsole==5.2.2\n",
            "QtPy==2.0.1\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.1\n",
            "resampy==0.2.2\n",
            "rpy2==3.4.5\n",
            "rsa==4.8\n",
            "scikit-image==0.18.3\n",
            "scikit-learn==1.0.2\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==3.2.0\n",
            "seaborn==0.11.2\n",
            "semver==2.13.0\n",
            "Send2Trash==1.8.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.8.1.post1\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.2.1\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "SoundFile==0.10.3.post1\n",
            "soupsieve==2.3.1\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.6\n",
            "sphinxcontrib-serializinghtml==1.1.5\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.32\n",
            "sqlparse==0.4.2\n",
            "srsly==1.0.5\n",
            "statsmodels==0.10.2\n",
            "sympy==1.7.1\n",
            "tables==3.7.0\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tenacity==8.0.1\n",
            "tensorboard==2.8.0\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.1\n",
            "tensorflow @ file:///tensorflow-2.8.0-cp37-cp37m-linux_x86_64.whl\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.8.0\n",
            "tensorflow-gcs-config==2.8.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-io-gcs-filesystem==0.24.0\n",
            "tensorflow-metadata==1.7.0\n",
            "tensorflow-probability==0.16.0\n",
            "termcolor==1.1.0\n",
            "terminado==0.13.3\n",
            "testpath==0.6.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "Theano-PyMC==1.1.2\n",
            "thinc==7.4.0\n",
            "threadpoolctl==3.1.0\n",
            "tifffile==2021.11.2\n",
            "tomli==2.0.1\n",
            "toolz==0.11.2\n",
            "torch @ https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
            "torchaudio @ https://download.pytorch.org/whl/cu111/torchaudio-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.11.0\n",
            "torchvision @ https://download.pytorch.org/whl/cu111/torchvision-0.11.1%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
            "tornado==5.1.1\n",
            "tqdm==4.63.0\n",
            "traitlets==5.1.1\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.10.0.2\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.9.0\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.6.0\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.14.0\n",
            "xarray==0.18.2\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==1.4\n",
            "zict==2.1.0\n",
            "zipp==3.7.0\n"
          ]
        }
      ],
      "source": [
        "%pip install fastai==2.5.3 -q\n",
        "%pip freeze"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from fastai.vision.all import *\n",
        "import sys"
      ],
      "metadata": {
        "id": "1JPm_NiTxqO9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vw-Wphv4xa0P"
      },
      "outputs": [],
      "source": [
        "# Load EB_ML python libraries\n",
        "# The following libraries are used in this notebook and should be installed in your local machine before running this notebook.\n",
        "# eb_colab_utils.py\n",
        "# eb_ml_battery_lib.py\n",
        "# eb_ml_utils.py\n",
        "\n",
        "# path to load external *.py files used in this notebook\n",
        "# Note: in Google Colab virtual machine you shoud copy the files in \"/content\" folder after BEFORE running this notebook's cell\n",
        "\n",
        "external_python_file_path=\"/content\"\n",
        "sys.path.append(external_python_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PKLZgvtOxa0Q"
      },
      "outputs": [],
      "source": [
        "from eb_ml_utils import build_data_loader,score_model\n",
        "from eb_ml_colab_utils import get_root_path\n",
        "from eb_ml_battery_lib import load_soc_dataset,generate_image_files_from_eis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment configuration "
      ],
      "metadata": {
        "id": "5FhF-7f5TLER"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfdsyJ5Uxa0R",
        "outputId": "5f6c4d74-1303-4df5-cd87-510ab63cbce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on COLAB\n",
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "#configuration dictionary\n",
        "config ={}\n",
        "\n",
        "# Root working folder (local or Google Drive)\n",
        "# config['ROOT_DIR'] = get_root_path(\"batterie\")\n",
        "config['ROOT_DIR'] = get_root_path(\"batterie\")  \n",
        "\n",
        "# Folder with dataset in CSV format\n",
        "#config['DATASETS_DIR'] = config['ROOT_DIR']+\"/datasets\"\n",
        "config['DATASETS_DIR'] = config['ROOT_DIR']+\"/datasets/EIS-vs-SOC-2022\"\n",
        "\n",
        "# List of SoC level into dataset\n",
        "config['soc_list']=['100','090','080','070','060','050','040','030','020','010']\n",
        "\n",
        "# Folder to store trained model\n",
        "#config['MODELS_DIR'] = config['ROOT_DIR']+\"/models\"\n",
        "config['MODELS_DIR'] = config['ROOT_DIR']+\"/models\"\n",
        "\n",
        "#TODO: nel dataset di validazione alcune classi non sono rappresentate. Usare stratified splitter\n",
        "config['Splitter'] = RandomSplitter(valid_pct=0.3, seed=41)\n",
        "config['rePat'] = r'^.*_(\\d+).png$'\n",
        "\n",
        "\n",
        "#Acquisizioni dati caricare per inferenza con modello addestrato\n",
        "test_battery_list=[[6],[13],[14]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image file generation for inference"
      ],
      "metadata": {
        "id": "ARDHhyvLTjZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ywRkSH3Xxa0T"
      },
      "outputs": [],
      "source": [
        "# Enable/disable image dataset generation\n",
        "# Image generation process consume time and computational resources. \n",
        "# You need to generate image just once test EIS data acquisition\n",
        "# generate_images = False\n",
        "generate_images = False\n",
        "\n",
        "# List EIS data acquistion that need image generation\n",
        "#image_dataset_to_be_generated=[6,13,14]\n",
        "image_dataset_to_be_generated=[]\n",
        "\n",
        "#GENERATE IMAGE\n",
        "if(generate_images):\n",
        "  for batt in image_dataset_to_be_generated:\n",
        "    config['ExperimentName']= \"BATTERY_\"+str(batt)\n",
        "    config['TEST_IMAGES_PATH']= config['ROOT_DIR']+\"/PaperEIS_PRODUCTION_DATA\"\n",
        "    test_dataset,feature_col_names=load_soc_dataset([batt],config[\"soc_list\"],config['DATASETS_DIR'])\n",
        "    generate_image_files_from_eis(test_dataset,feature_col_names,config['TEST_IMAGES_PATH'],config['ExperimentName'],DATA_AUGMENTATION_FACTOR=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Ensamble\n",
        "\n",
        "Inference with model ensamble on Test Data "
      ],
      "metadata": {
        "id": "tjv47-_a1CU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source data: battery EIS performed for SoC 100,90,80,70,60,50,40,30,20,10. Same frequnecies for each SoC\n",
        "\n",
        "Data format:  Re{Zbat}-Im{Zbat}j\n",
        "\n",
        "Data Acquisition:\n",
        "\n",
        "1. Batt1/Meas1\n",
        "2. Batt1/Meas2\n",
        "3. Batt2/Meas1 \n",
        "4. Batt2/Meas2\n",
        "5. Batt3/Meas1\n",
        "6. Batt3/Meas2 --> TEST\n",
        "7. Batt4/Meas1\n",
        "8. Batt5/Meas1\n",
        "9. Batt6/Meas1 \n",
        "10. Batt7/Meas1\n",
        "11. Batt8/Meas1\n",
        "12. Batt9/Meas1\n",
        "13. Batt10/Meas1 -->TEST\n",
        "14. Batt4/Meas2 -->TEST\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UWV-LqvaqKM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiments=['Paper_EIS_leave_one_out_1','Paper_EIS_leave_one_out_2','Paper_EIS_leave_one_out_3','Paper_EIS_leave_one_out_4','Paper_EIS_leave_one_out_5','Paper_EIS_leave_one_out_6','Paper_EIS_leave_one_out_7','Paper_EIS_leave_one_out_8','Paper_EIS_leave_one_out_9'] # Measurement 6,13 for test]\n",
        "saved_weights_files= ['/gdrive/MyDrive/batterie/models/Paper_EIS_leave_one_out_1_1648917854.175632_SAVED',\n",
        "                      '/gdrive/MyDrive/batterie/models/Paper_EIS_leave_one_out_2_1648918402.165991_SAVED',\n",
        "                      '/gdrive/MyDrive/batterie/models/Paper_EIS_leave_one_out_3_1648919027.947993_SAVED',\n",
        "                      '/gdrive/MyDrive/batterie/models/Paper_EIS_leave_one_out_4_1648919640.51975_SAVED',\n",
        "                      '/gdrive/MyDrive/batterie/models/Paper_EIS_leave_one_out_5_1648920276.006414_SAVED',\n",
        "                      '/gdrive/MyDrive/batterie/models/Paper_EIS_leave_one_out_6_1648920920.623353_SAVED',\n",
        "                      '/gdrive/MyDrive/batterie/models/Paper_EIS_leave_one_out_7_1648921586.201785_SAVED',\n",
        "                      '/gdrive/MyDrive/batterie/models/Paper_EIS_leave_one_out_8_1648922259.048984_SAVED',\n",
        "                      '/gdrive/MyDrive/batterie/models/Paper_EIS_leave_one_out_9_1648922951.265163_SAVED'\n",
        "                      #TODO: 6,13,14 for test\n",
        "                      ]\n"
      ],
      "metadata": {
        "id": "jfojtJL41CCK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference on new data acquisition on battery 3 (EIS Data acquisition n. 6. Battery 3 measurement 2)"
      ],
      "metadata": {
        "id": "QqnaOgQWD-2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiments_predictions = []\n",
        "experiments_predictions_decoded=[]\n",
        "\n",
        "exeperiments_targets = []\n",
        "\n",
        "models_accuracy = []\n",
        "\n",
        "models_top2_accuracy = []\n",
        "\n",
        "config['TEST_IMAGES_PATH']= config['ROOT_DIR']+\"/PaperEIS_PRODUCTION_DATA/BATTERY_6\"\n",
        "test_fnames= get_image_files(config[\"TEST_IMAGES_PATH\"])\n",
        "for experiment_index in range(0,len(experiments),1):\n",
        "  print(\"ExperimentName: \"+str(experiments[experiment_index]))\n",
        "  saved_weights=saved_weights_files[experiment_index]\n",
        "  config['ExperimentName'] = experiments[experiment_index]\n",
        "  config['IMAGES_PATH'] = config['ROOT_DIR']+\"/\"+config['ExperimentName']\n",
        "\n",
        "  # BUILD DATA LOADER\n",
        "  dl=build_data_loader(config)\n",
        "\n",
        "  # BUILD LEARNER\n",
        "  learn = cnn_learner(dl, resnet18, metrics=accuracy)\n",
        "\n",
        "  learn = learn.load(saved_weights)\n",
        "\n",
        "  # SCORE MODEL\n",
        "  #score_model(saved_weights,dl)\n",
        "\n",
        "  \n",
        "  test_dl = learn.dls.test_dl(test_fnames,with_labels=True)\n",
        "  predictions, targets, decoded = learn.get_preds(dl=test_dl, with_decoded=True)\n",
        "  experiments_predictions.append(predictions)\n",
        "  experiments_predictions_decoded.append(decoded)\n",
        "  exeperiments_targets.append(targets)\n",
        "  model_accuracy= accuracy(predictions,targets)\n",
        "  models_accuracy.append(model_accuracy)\n",
        "  from sklearn.metrics import top_k_accuracy_score\n",
        "  model_top2_accuracy= top_k_accuracy_score(targets, predictions, k=2)\n",
        "  models_top2_accuracy.append(model_top2_accuracy)\n",
        "  print(\"model_accuracy: \" + str(model_accuracy))\n",
        "  print(\"model_top2_accuracy: \" + str(model_top2_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9c13ab42-1716-42b4-cd95-56199787e404",
        "id": "loNeEkIVEEhG"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExperimentName: Paper_EIS_leave_one_out_1\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_1\n",
            "Found 900 items\n",
            "2 datasets of sizes 630,270\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_1/Paper_EIS_leave_one_out_1/Batt_1710_030.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_1/Paper_EIS_leave_one_out_1/Batt_1710_030.png\n",
            "    applying RegexLabeller gives\n",
            "      030\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(2)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(2))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_1\n",
            "Found 900 items\n",
            "2 datasets of sizes 630,270\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(2))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(2))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(2))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.6000)\n",
            "model_top2_accuracy: 0.8\n",
            "ExperimentName: Paper_EIS_leave_one_out_2\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_2\n",
            "Found 900 items\n",
            "2 datasets of sizes 630,270\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_2/Paper_EIS_leave_one_out_2/Batt_1710_030.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_2/Paper_EIS_leave_one_out_2/Batt_1710_030.png\n",
            "    applying RegexLabeller gives\n",
            "      030\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(2)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(2))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_2\n",
            "Found 900 items\n",
            "2 datasets of sizes 630,270\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(2))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(2))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(2))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.6000)\n",
            "model_top2_accuracy: 0.9\n",
            "ExperimentName: Paper_EIS_leave_one_out_3\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_3\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_3/Paper_EIS_leave_one_out_3/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_3/Paper_EIS_leave_one_out_3/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_3\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.6000)\n",
            "model_top2_accuracy: 0.9\n",
            "ExperimentName: Paper_EIS_leave_one_out_4\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_4\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_4/Paper_EIS_leave_one_out_4/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_4/Paper_EIS_leave_one_out_4/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_4\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.7000)\n",
            "model_top2_accuracy: 0.9\n",
            "ExperimentName: Paper_EIS_leave_one_out_5\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_5\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_5/Paper_EIS_leave_one_out_5/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_5/Paper_EIS_leave_one_out_5/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_5\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.5000)\n",
            "model_top2_accuracy: 0.8\n",
            "ExperimentName: Paper_EIS_leave_one_out_6\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_6\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_6/Paper_EIS_leave_one_out_6/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_6/Paper_EIS_leave_one_out_6/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_6\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.6000)\n",
            "model_top2_accuracy: 0.9\n",
            "ExperimentName: Paper_EIS_leave_one_out_7\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_7\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_7/Paper_EIS_leave_one_out_7/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_7/Paper_EIS_leave_one_out_7/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_7\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.6000)\n",
            "model_top2_accuracy: 1.0\n",
            "ExperimentName: Paper_EIS_leave_one_out_8\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_8\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_8/Paper_EIS_leave_one_out_8/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_8/Paper_EIS_leave_one_out_8/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_8\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.9000)\n",
            "model_top2_accuracy: 0.9\n",
            "ExperimentName: Paper_EIS_leave_one_out_9\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_9\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_9/Paper_EIS_leave_one_out_9/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_9/Paper_EIS_leave_one_out_9/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_9\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.5000)\n",
            "model_top2_accuracy: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5d9NFVzESqN",
        "outputId": "830be24b-3523-4812-e431-fc82b322e117"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TensorBase(0.6000),\n",
              " TensorBase(0.6000),\n",
              " TensorBase(0.6000),\n",
              " TensorBase(0.7000),\n",
              " TensorBase(0.5000),\n",
              " TensorBase(0.6000),\n",
              " TensorBase(0.6000),\n",
              " TensorBase(0.9000),\n",
              " TensorBase(0.5000)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(models_accuracy)"
      ],
      "metadata": {
        "id": "K-H_6hvgPcfZ",
        "outputId": "67941309-205c-4c75-b64a-73e1b61c6ef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6222222"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_top2_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7O-RzXXEYLC",
        "outputId": "94405184-3a6d-4b56-92f2-96ac168cda54"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8, 0.9, 0.9, 0.9, 0.8, 0.9, 1.0, 0.9, 0.9]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(models_top2_accuracy)"
      ],
      "metadata": {
        "id": "gBTqzv08PiUP",
        "outputId": "c43fceca-3459-4b02-b876-b22e091f5617",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8888888888888888"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate ensable prediction\n",
        "ensamble_prediction = experiments_predictions[0]\n",
        "for pred in experiments_predictions[1:]:\n",
        "  ensamble_prediction += pred\n",
        "\n",
        "ensamble_prediction /= len(experiments_predictions)\n",
        "#ensamble_accuracy\n",
        "accuracy(ensamble_prediction, exeperiments_targets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoA8r8lmEnaU",
        "outputId": "98f3f4a3-2701-47be-dc1d-cc16041323f3"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(0.6000)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference on new battery (EIS data acquistion n. 13. Battery 10 - Measurement 1)"
      ],
      "metadata": {
        "id": "it7EPonXX2DA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiments_predictions = []\n",
        "\n",
        "exeperiments_targets = []\n",
        "\n",
        "models_accuracy = []\n",
        "\n",
        "models_top2_accuracy = []\n",
        "\n",
        "config['TEST_IMAGES_PATH']= config['ROOT_DIR']+\"/PaperEIS_PRODUCTION_DATA/BATTERY_13\"\n",
        "test_fnames= get_image_files(config[\"TEST_IMAGES_PATH\"])\n",
        "for experiment_index in range(0,len(experiments),1):\n",
        "  print(\"ExperimentName: \"+str(experiments[experiment_index]))\n",
        "  saved_weights=saved_weights_files[experiment_index]\n",
        "  config['ExperimentName'] = experiments[experiment_index]\n",
        "  config['IMAGES_PATH'] = config['ROOT_DIR']+\"/\"+config['ExperimentName']\n",
        "\n",
        "  # BUILD DATA LOADER\n",
        "  dl=build_data_loader(config)\n",
        "\n",
        "  # BUILD LEARNER\n",
        "  learn = cnn_learner(dl, resnet18, metrics=accuracy)\n",
        "\n",
        "  learn = learn.load(saved_weights)\n",
        "\n",
        "  # SCORE MODEL\n",
        "  #score_model(saved_weights,dl)\n",
        "\n",
        "  \n",
        "  test_dl = learn.dls.test_dl(test_fnames,with_labels=True)\n",
        "  predictions, targets, decoded = learn.get_preds(dl=test_dl, with_decoded=True)\n",
        "  experiments_predictions.append(predictions)\n",
        "  exeperiments_targets.append(targets)\n",
        "  model_accuracy= accuracy(predictions,targets)\n",
        "  models_accuracy.append(model_accuracy)\n",
        "  from sklearn.metrics import top_k_accuracy_score\n",
        "  model_top2_accuracy= top_k_accuracy_score(targets, predictions, k=2)\n",
        "  models_top2_accuracy.append(model_top2_accuracy)\n",
        "  print(\"model_accuracy: \" + str(model_accuracy))\n",
        "  print(\"model_top2_accuracy: \" + str(model_top2_accuracy))"
      ],
      "metadata": {
        "id": "hZWND3VG1NQ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6cf949e5c3dc4955bb348b1108fee765",
            "a32ab5706ad1420b9515f297287b2441",
            "ac8c952643994cb59f38b5242ffcd53b",
            "075b5a1a20d94356816f256f4394647c",
            "04a143af27b247abb439c6c4d0eb5f7c",
            "d1e6eb70f0384e2ebbaa262004d5eab9",
            "0a6b86ce0bd64cd79f0552f3b38127c2",
            "d440ec982b1846c8af6da49e39715fda",
            "b714bdfb115744fab58b70a855b9afb9",
            "cd216a95c09e41f59ecbd2f6ad5b9f9b",
            "49e8b3f239a84a26bd0fdf35727ccdac"
          ]
        },
        "outputId": "25213a64-30cd-4873-c922-f0e8bb4c5486"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExperimentName: Paper_EIS_leave_one_out_1\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_1\n",
            "Found 900 items\n",
            "2 datasets of sizes 630,270\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_1/Paper_EIS_leave_one_out_1/Batt_1710_030.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_1/Paper_EIS_leave_one_out_1/Batt_1710_030.png\n",
            "    applying RegexLabeller gives\n",
            "      030\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(2)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(2))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_1\n",
            "Found 900 items\n",
            "2 datasets of sizes 630,270\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(2))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(2))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(2))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cf949e5c3dc4955bb348b1108fee765"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.8000)\n",
            "model_top2_accuracy: 0.8\n",
            "ExperimentName: Paper_EIS_leave_one_out_2\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_2\n",
            "Found 900 items\n",
            "2 datasets of sizes 630,270\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_2/Paper_EIS_leave_one_out_2/Batt_1710_030.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_2/Paper_EIS_leave_one_out_2/Batt_1710_030.png\n",
            "    applying RegexLabeller gives\n",
            "      030\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(2)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(2))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_2\n",
            "Found 900 items\n",
            "2 datasets of sizes 630,270\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(2))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(2))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(2))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.7000)\n",
            "model_top2_accuracy: 1.0\n",
            "ExperimentName: Paper_EIS_leave_one_out_3\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_3\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_3/Paper_EIS_leave_one_out_3/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_3/Paper_EIS_leave_one_out_3/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_3\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.6000)\n",
            "model_top2_accuracy: 1.0\n",
            "ExperimentName: Paper_EIS_leave_one_out_4\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_4\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_4/Paper_EIS_leave_one_out_4/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_4/Paper_EIS_leave_one_out_4/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_4\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.7000)\n",
            "model_top2_accuracy: 1.0\n",
            "ExperimentName: Paper_EIS_leave_one_out_5\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_5\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_5/Paper_EIS_leave_one_out_5/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_5/Paper_EIS_leave_one_out_5/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_5\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.8000)\n",
            "model_top2_accuracy: 0.9\n",
            "ExperimentName: Paper_EIS_leave_one_out_6\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_6\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_6/Paper_EIS_leave_one_out_6/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_6/Paper_EIS_leave_one_out_6/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_6\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.7000)\n",
            "model_top2_accuracy: 1.0\n",
            "ExperimentName: Paper_EIS_leave_one_out_7\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_7\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_7/Paper_EIS_leave_one_out_7/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_7/Paper_EIS_leave_one_out_7/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_7\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.5000)\n",
            "model_top2_accuracy: 0.8\n",
            "ExperimentName: Paper_EIS_leave_one_out_8\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_8\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_8/Paper_EIS_leave_one_out_8/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_8/Paper_EIS_leave_one_out_8/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_8\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.8000)\n",
            "model_top2_accuracy: 1.0\n",
            "ExperimentName: Paper_EIS_leave_one_out_9\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_9\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_9/Paper_EIS_leave_one_out_9/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_9/Paper_EIS_leave_one_out_9/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_9\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.7000)\n",
            "model_top2_accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjnUlVy0sFzJ",
        "outputId": "c1bb5c88-b513-48ff-d2b7-5fedd928d001"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TensorBase(0.8000),\n",
              " TensorBase(0.7000),\n",
              " TensorBase(0.6000),\n",
              " TensorBase(0.7000),\n",
              " TensorBase(0.8000),\n",
              " TensorBase(0.7000),\n",
              " TensorBase(0.5000),\n",
              " TensorBase(0.8000),\n",
              " TensorBase(0.7000)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(models_accuracy)"
      ],
      "metadata": {
        "id": "QHT8UEl9QHW4",
        "outputId": "87188460-6749-4851-a46e-981a3d0246ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6222222"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_top2_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRtY7GMAtDS5",
        "outputId": "b07eb1f7-1b11-483b-9adc-282805d79f4c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8, 1.0, 1.0, 1.0, 0.9, 1.0, 0.8, 1.0, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(models_top2_accuracy)"
      ],
      "metadata": {
        "id": "V-8BS89PQKSu",
        "outputId": "85279df3-ec7d-4330-fb55-91cf7a0787d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8888888888888888"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate ensable prediction\n",
        "ensamble_prediction = experiments_predictions[0]\n",
        "for pred in experiments_predictions[1:]:\n",
        "  ensamble_prediction += pred"
      ],
      "metadata": {
        "id": "hUTEzpEn1S3x"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensamble_prediction /= len(experiments_predictions)\n",
        "#ensamble_accuracy\n",
        "accuracy(ensamble_prediction, exeperiments_targets[0])"
      ],
      "metadata": {
        "id": "MaR85O_T1Tym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9642d6c-a7b2-4c89-d6da-ac3bd627f515"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(0.7000)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ensamble top2 accuracy\n",
        "top_k_accuracy_score(exeperiments_targets[0], ensamble_prediction, k=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUU9qCB3tRdY",
        "outputId": "ce02a47b-e7f9-4ce7-8513-33b987c85d17"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference on new data acquisition on battery 4 (EIS Data acquisition n. 14. Battery 4 measurement 2)"
      ],
      "metadata": {
        "id": "vJrf6J3uXW77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiments_predictions = []\n",
        "\n",
        "exeperiments_targets = []\n",
        "\n",
        "models_accuracy = []\n",
        "\n",
        "models_top2_accuracy = []\n",
        "\n",
        "config['TEST_IMAGES_PATH']= config['ROOT_DIR']+\"/PaperEIS_PRODUCTION_DATA/BATTERY_14\"\n",
        "test_fnames= get_image_files(config[\"TEST_IMAGES_PATH\"])\n",
        "for experiment_index in range(0,len(experiments),1):\n",
        "  print(\"ExperimentName: \"+str(experiments[experiment_index]))\n",
        "  saved_weights=saved_weights_files[experiment_index]\n",
        "  config['ExperimentName'] = experiments[experiment_index]\n",
        "  config['IMAGES_PATH'] = config['ROOT_DIR']+\"/\"+config['ExperimentName']\n",
        "\n",
        "  # BUILD DATA LOADER\n",
        "  dl=build_data_loader(config)\n",
        "\n",
        "  # BUILD LEARNER\n",
        "  learn = cnn_learner(dl, resnet18, metrics=accuracy)\n",
        "\n",
        "  learn = learn.load(saved_weights)\n",
        "\n",
        "  # SCORE MODEL\n",
        "  #score_model(saved_weights,dl)\n",
        "\n",
        "  \n",
        "  test_dl = learn.dls.test_dl(test_fnames,with_labels=True)\n",
        "  predictions, targets, decoded = learn.get_preds(dl=test_dl, with_decoded=True)\n",
        "  experiments_predictions.append(predictions)\n",
        "  exeperiments_targets.append(targets)\n",
        "  model_accuracy= accuracy(predictions,targets)\n",
        "  models_accuracy.append(model_accuracy)\n",
        "  from sklearn.metrics import top_k_accuracy_score\n",
        "  model_top2_accuracy= top_k_accuracy_score(targets, predictions, k=2)\n",
        "  models_top2_accuracy.append(model_top2_accuracy)\n",
        "  print(\"model_accuracy: \" + str(model_accuracy))\n",
        "  print(\"model_top2_accuracy: \" + str(model_top2_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1a0920d-1726-4f16-87fc-b7c8da90dfa4",
        "id": "rwsfCV01XUFb"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExperimentName: Paper_EIS_leave_one_out_1\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_1\n",
            "Found 900 items\n",
            "2 datasets of sizes 630,270\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_1/Paper_EIS_leave_one_out_1/Batt_1710_030.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_1/Paper_EIS_leave_one_out_1/Batt_1710_030.png\n",
            "    applying RegexLabeller gives\n",
            "      030\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(2)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(2))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_1\n",
            "Found 900 items\n",
            "2 datasets of sizes 630,270\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(2))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(2))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(2))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.5000)\n",
            "model_top2_accuracy: 0.7\n",
            "ExperimentName: Paper_EIS_leave_one_out_2\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_2\n",
            "Found 900 items\n",
            "2 datasets of sizes 630,270\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_2/Paper_EIS_leave_one_out_2/Batt_1710_030.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_2/Paper_EIS_leave_one_out_2/Batt_1710_030.png\n",
            "    applying RegexLabeller gives\n",
            "      030\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(2)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(2))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_2\n",
            "Found 900 items\n",
            "2 datasets of sizes 630,270\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(2))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(2))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(2))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([2, 7, 7, 1], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.2000)\n",
            "model_top2_accuracy: 0.7\n",
            "ExperimentName: Paper_EIS_leave_one_out_3\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_3\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_3/Paper_EIS_leave_one_out_3/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_3/Paper_EIS_leave_one_out_3/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_3\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.5000)\n",
            "model_top2_accuracy: 0.6\n",
            "ExperimentName: Paper_EIS_leave_one_out_4\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_4\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_4/Paper_EIS_leave_one_out_4/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_4/Paper_EIS_leave_one_out_4/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_4\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.4000)\n",
            "model_top2_accuracy: 0.6\n",
            "ExperimentName: Paper_EIS_leave_one_out_5\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_5\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_5/Paper_EIS_leave_one_out_5/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_5/Paper_EIS_leave_one_out_5/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_5\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.4000)\n",
            "model_top2_accuracy: 0.8\n",
            "ExperimentName: Paper_EIS_leave_one_out_6\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_6\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_6/Paper_EIS_leave_one_out_6/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_6/Paper_EIS_leave_one_out_6/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_6\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.5000)\n",
            "model_top2_accuracy: 0.7\n",
            "ExperimentName: Paper_EIS_leave_one_out_7\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_7\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_7/Paper_EIS_leave_one_out_7/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_7/Paper_EIS_leave_one_out_7/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_7\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.4000)\n",
            "model_top2_accuracy: 0.7\n",
            "ExperimentName: Paper_EIS_leave_one_out_8\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_8\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_8/Paper_EIS_leave_one_out_8/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_8/Paper_EIS_leave_one_out_8/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_8\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.6000)\n",
            "model_top2_accuracy: 0.8\n",
            "ExperimentName: Paper_EIS_leave_one_out_9\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_9\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_9/Paper_EIS_leave_one_out_9/Batt_1702_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_9/Paper_EIS_leave_one_out_9/Batt_1702_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_9\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.4000)\n",
            "model_top2_accuracy: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_accuracy"
      ],
      "metadata": {
        "id": "XUgcPINxYffl",
        "outputId": "904591ad-99c0-4c7d-fde2-4c629d26d286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TensorBase(0.5000),\n",
              " TensorBase(0.2000),\n",
              " TensorBase(0.5000),\n",
              " TensorBase(0.4000),\n",
              " TensorBase(0.4000),\n",
              " TensorBase(0.5000),\n",
              " TensorBase(0.4000),\n",
              " TensorBase(0.6000),\n",
              " TensorBase(0.4000)]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(models_accuracy)"
      ],
      "metadata": {
        "id": "misOYS08PwSF",
        "outputId": "7ceae0df-a5af-4b5a-edf3-e547e51616e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43333334"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_top2_accuracy"
      ],
      "metadata": {
        "id": "yWxfnQK0Yffm",
        "outputId": "9eff40bf-68c2-413c-c80a-ec262cc1b04a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7, 0.7, 0.6, 0.6, 0.8, 0.7, 0.7, 0.8, 0.7]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(models_top2_accuracy)"
      ],
      "metadata": {
        "id": "ZnxaFKbJP25A",
        "outputId": "f6ac1243-0f1a-4298-9969-6bdaedf58dc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate ensable prediction\n",
        "ensamble_prediction = experiments_predictions[0]\n",
        "for pred in experiments_predictions[1:]:\n",
        "  ensamble_prediction += pred\n",
        "\n",
        "ensamble_prediction /= len(experiments_predictions)\n",
        "#ensamble_accuracy\n",
        "accuracy(ensamble_prediction, exeperiments_targets[0])"
      ],
      "metadata": {
        "id": "Su_0Dcj6Yffm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07dcc56a-cd08-460c-f045-3ebeae9be5c0"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(0.4000)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ensamble top2 accuracy\n",
        "top_k_accuracy_score(exeperiments_targets[0], ensamble_prediction, k=2)"
      ],
      "metadata": {
        "id": "dC54B2UmYffm",
        "outputId": "65993508-991c-4081-9b56-127c5c744cd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Model - Training/Validation split\n",
        "\n",
        "Modello addestrato con tutti i dati tranne batteria 3 e 10"
      ],
      "metadata": {
        "id": "o1aZkmU9QZb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model trained on data acquisition from batteries 1,2,4,5,6,7,8,9\n",
        "# acquistion from batteries 3 and 10 used only for inference test\n",
        "saved_weights = \"/gdrive/MyDrive/batterie/models/Paper_EIS_single_model_1648968761.170263_SAVED\"\n",
        "\n",
        "config['ExperimentName'] = \"PaperEIS_3\"\n",
        "config['IMAGES_PATH'] = config['ROOT_DIR']+\"/\"+config['ExperimentName']"
      ],
      "metadata": {
        "id": "cflLfcHwydMb"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test on new data acquisition on battery 3"
      ],
      "metadata": {
        "id": "jUEfs9KOjdfI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95a31e1f-aeea-4e6d-d1f3-886c98cda99c",
        "id": "fWlqwVTljiMP"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/PaperEIS_3\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/PaperEIS_3/PaperEIS_3/Batt_1027_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/PaperEIS_3/PaperEIS_3/Batt_1027_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/PaperEIS_3\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.8000)\n",
            "model_top2_accuracy: 0.9\n"
          ]
        }
      ],
      "source": [
        "config['TEST_IMAGES_PATH']= config['ROOT_DIR']+\"/PaperEIS_PRODUCTION_DATA/BATTERY_6\"\n",
        "test_fnames= get_image_files(config[\"TEST_IMAGES_PATH\"])\n",
        "#DATA LOADER\n",
        "dl=build_data_loader(config)\n",
        "\n",
        "# BUILD LEARNER\n",
        "learn = cnn_learner(dl, resnet18, metrics=accuracy)\n",
        "\n",
        "learn = learn.load(saved_weights)\n",
        "\n",
        "test_dl = learn.dls.test_dl(test_fnames,with_labels=True)\n",
        "predictions, targets, decoded = learn.get_preds(dl=test_dl, with_decoded=True)\n",
        "model_accuracy= accuracy(predictions,targets)\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "model_top2_accuracy= top_k_accuracy_score(targets, predictions, k=2)\n",
        "print(\"model_accuracy: \" + str(model_accuracy))\n",
        "print(\"model_top2_accuracy: \" + str(model_top2_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SCORE MODEL\n",
        "score_model(saved_weights,dl)"
      ],
      "metadata": {
        "id": "4OziE4PGjyiX",
        "outputId": "1252fcfb-03e6-4627-f87c-0880a97c332a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[26  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 36  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 27  0  3  0  0  0  0  0]\n",
            " [ 0  3  0 33  0  0  0  0  0  0]\n",
            " [ 0  2  0  0 25  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 28  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 26  2  0  0]\n",
            " [ 0  0  0  0  0  0  1 22  5  0]\n",
            " [ 0  0  0  0  0  0  0  0 35  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 26]]\n",
            "[[1.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         1.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.9        0.         0.1        0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.08333333 0.         0.91666667 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.07407407 0.         0.         0.92592593 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.92857143 0.07142857 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.03571429 0.78571429 0.17857143 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         1.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         1.        ]]\n",
            "interpretation.most_confused()\n",
            "interpretation.top_losses()\n",
            "interpretation.print_classification_report()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         010       1.00      1.00      1.00        26\n",
            "         020       0.88      1.00      0.94        36\n",
            "         030       1.00      0.90      0.95        30\n",
            "         040       1.00      0.92      0.96        36\n",
            "         050       0.89      0.93      0.91        27\n",
            "         060       1.00      1.00      1.00        28\n",
            "         070       0.96      0.93      0.95        28\n",
            "         080       0.92      0.79      0.85        28\n",
            "         090       0.88      1.00      0.93        35\n",
            "         100       1.00      1.00      1.00        26\n",
            "\n",
            "    accuracy                           0.95       300\n",
            "   macro avg       0.95      0.95      0.95       300\n",
            "weighted avg       0.95      0.95      0.95       300\n",
            "\n",
            "learn.show_results()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learn.validate()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 0.95\n",
            "learn.get_preds()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(0.9467)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test on new battery (battery 10)"
      ],
      "metadata": {
        "id": "D6khANrejTYF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XFZ1w6t7xa0T",
        "outputId": "64454980-99f1-4ac6-8ab8-d963628e0856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/PaperEIS_3\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/PaperEIS_3/PaperEIS_3/Batt_1027_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/PaperEIS_3/PaperEIS_3/Batt_1027_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/PaperEIS_3\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.6000)\n",
            "model_top2_accuracy: 0.9\n"
          ]
        }
      ],
      "source": [
        "config['TEST_IMAGES_PATH']= config['ROOT_DIR']+\"/PaperEIS_PRODUCTION_DATA/BATTERY_13\"\n",
        "test_fnames= get_image_files(config[\"TEST_IMAGES_PATH\"])\n",
        "#DATA LOADER\n",
        "dl=build_data_loader(config)\n",
        "\n",
        "# BUILD LEARNER\n",
        "learn = cnn_learner(dl, resnet18, metrics=accuracy)\n",
        "\n",
        "learn = learn.load(saved_weights)\n",
        "\n",
        "test_dl = learn.dls.test_dl(test_fnames,with_labels=True)\n",
        "predictions, targets, decoded = learn.get_preds(dl=test_dl, with_decoded=True)\n",
        "model_accuracy= accuracy(predictions,targets)\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "model_top2_accuracy= top_k_accuracy_score(targets, predictions, k=2)\n",
        "print(\"model_accuracy: \" + str(model_accuracy))\n",
        "print(\"model_top2_accuracy: \" + str(model_top2_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test on new battery 4 measurement (EIS Data acquisition 14, Battery 4 - measurement 2)"
      ],
      "metadata": {
        "id": "Xww9FJTjIos1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34352bda-91e5-45c8-fcaf-9f5ad584cd8e",
        "id": "ZHsmx_KEIoCe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/PaperEIS_3\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/PaperEIS_3/PaperEIS_3/Batt_1027_010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/PaperEIS_3/PaperEIS_3/Batt_1027_010.png\n",
            "    applying RegexLabeller gives\n",
            "      010\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/PaperEIS_3\n",
            "Found 1000 items\n",
            "2 datasets of sizes 700,300\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(0))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([0, 2, 6, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.5000)\n",
            "model_top2_accuracy: 0.6\n"
          ]
        }
      ],
      "source": [
        "config['TEST_IMAGES_PATH']= config['ROOT_DIR']+\"/PaperEIS_PRODUCTION_DATA/BATTERY_14\"\n",
        "test_fnames= get_image_files(config[\"TEST_IMAGES_PATH\"])\n",
        "#DATA LOADER\n",
        "dl=build_data_loader(config)\n",
        "\n",
        "# BUILD LEARNER\n",
        "learn = cnn_learner(dl, resnet18, metrics=accuracy)\n",
        "\n",
        "learn = learn.load(saved_weights)\n",
        "\n",
        "test_dl = learn.dls.test_dl(test_fnames,with_labels=True)\n",
        "predictions, targets, decoded = learn.get_preds(dl=test_dl, with_decoded=True)\n",
        "model_accuracy= accuracy(predictions,targets)\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "model_top2_accuracy= top_k_accuracy_score(targets, predictions, k=2)\n",
        "print(\"model_accuracy: \" + str(model_accuracy))\n",
        "print(\"model_top2_accuracy: \" + str(model_top2_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_analog_value(prediction_output,learner):\n",
        "  ind = np.argsort(prediction_output)\n",
        "  value1 = prediction_output[ind[len(prediction_output)-1]]\n",
        "  print(value1)\n",
        "  value2 = prediction_output[ind[len(prediction_output)-2]]\n",
        "  print(value2)\n",
        "\n",
        "  classIndex1= ind[len(prediction_output)-1]\n",
        "  print(classIndex1)\n",
        "\n",
        "  classIndex2= ind[len(prediction_output)-2]\n",
        "  print(classIndex2)\n",
        "\n",
        "  avg_value= (int(learner.dls.vocab[classIndex2]) * value2) + (int(learner.dls.vocab[classIndex1]) * value1)\n",
        "  return avg_value"
      ],
      "metadata": {
        "id": "8KS1B35OJoMP"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "id": "NB0M08bgJqTv",
        "outputId": "6f8d53fb-4e19-42f7-85f7-ca62538d1577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorCategory([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind=np.argsort(predictions[0])"
      ],
      "metadata": {
        "id": "EQij-NgpKGaK"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind"
      ],
      "metadata": {
        "id": "4R2K5GUXLfXq",
        "outputId": "4c88f04c-7ec7-48ae-cfb7-a995c2815e5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase([5, 7, 8, 6, 4, 2, 3, 0, 1, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value1 = predictions[0][ind[len(predictions[0])-1]]"
      ],
      "metadata": {
        "id": "jogrxq6bKRY9"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value1"
      ],
      "metadata": {
        "id": "WWGYO_EGKlHE",
        "outputId": "cd26e34f-8450-4988-e436-d7fbd9d43bdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(0.7482)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value2 = predictions[0][ind[len(predictions[0])-2]]"
      ],
      "metadata": {
        "id": "RUPpGIKwKgYX"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value2"
      ],
      "metadata": {
        "id": "BfG9yLYKK3sy",
        "outputId": "dfada3d1-f1c5-4fce-d029-73f1f16a9cd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(0.2101)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classIndex1= ind[len(predictions[0])-1]\n",
        "print(classIndex1)\n",
        "\n",
        "classIndex2= ind[len(predictions[0])-2]\n",
        "print(classIndex2)\n"
      ],
      "metadata": {
        "id": "pMFlEzAdML1v",
        "outputId": "40006a09-9c0b-47ad-c9ea-4d7a83807ae8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorBase(9)\n",
            "TensorBase(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0]"
      ],
      "metadata": {
        "id": "Ddq0RiaRJ0_B",
        "outputId": "95d43178-1844-400e-fdb9-5721334aaf98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase([3.4467e-02, 2.1010e-01, 3.5740e-04, 6.6932e-03, 1.8766e-04, 6.3845e-08,\n",
              "        3.8220e-06, 9.1486e-07, 9.7353e-07, 7.4819e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn\n"
      ],
      "metadata": {
        "id": "qsO88t4sMiCz",
        "outputId": "a3e40cb3-810a-46ec-f075-c3a1acdaebfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.learner.Learner at 0x7fae0c1644d0>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  avg_value= (int(learn.dls.vocab[classIndex2]) * value2) + (int(learn.dls.vocab[classIndex1]) * value1)"
      ],
      "metadata": {
        "id": "MWkIxsgdMjtS"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_value"
      ],
      "metadata": {
        "id": "ojcb1cT7MvSC",
        "outputId": "5bf4e781-1b8d-4642-d724-3612541df9e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(79.0211)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_analog_value(predictions[0],learn)"
      ],
      "metadata": {
        "id": "VKdlduRaNKWo",
        "outputId": "be5ec624-3dc1-4cf3-fcbb-a64dd5eb84c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorBase(0.7482)\n",
            "TensorBase(0.2101)\n",
            "TensorBase(9)\n",
            "TensorBase(1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(79.0211)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_analog_value(predictions[1],learn)"
      ],
      "metadata": {
        "id": "pXJl0czTNYau",
        "outputId": "30dea780-d1f2-460a-cb54-8106cfcb3410",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorBase(0.8190)\n",
            "TensorBase(0.1810)\n",
            "TensorBase(0)\n",
            "TensorBase(1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(11.8096)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Paper_EIS_inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6cf949e5c3dc4955bb348b1108fee765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a32ab5706ad1420b9515f297287b2441",
              "IPY_MODEL_ac8c952643994cb59f38b5242ffcd53b",
              "IPY_MODEL_075b5a1a20d94356816f256f4394647c"
            ],
            "layout": "IPY_MODEL_04a143af27b247abb439c6c4d0eb5f7c"
          }
        },
        "a32ab5706ad1420b9515f297287b2441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1e6eb70f0384e2ebbaa262004d5eab9",
            "placeholder": "​",
            "style": "IPY_MODEL_0a6b86ce0bd64cd79f0552f3b38127c2",
            "value": "100%"
          }
        },
        "ac8c952643994cb59f38b5242ffcd53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d440ec982b1846c8af6da49e39715fda",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b714bdfb115744fab58b70a855b9afb9",
            "value": 46830571
          }
        },
        "075b5a1a20d94356816f256f4394647c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd216a95c09e41f59ecbd2f6ad5b9f9b",
            "placeholder": "​",
            "style": "IPY_MODEL_49e8b3f239a84a26bd0fdf35727ccdac",
            "value": " 44.7M/44.7M [00:01&lt;00:00, 34.9MB/s]"
          }
        },
        "04a143af27b247abb439c6c4d0eb5f7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1e6eb70f0384e2ebbaa262004d5eab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a6b86ce0bd64cd79f0552f3b38127c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d440ec982b1846c8af6da49e39715fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b714bdfb115744fab58b70a855b9afb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd216a95c09e41f59ecbd2f6ad5b9f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49e8b3f239a84a26bd0fdf35727ccdac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}