{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#SoC Classification Inference"
      ],
      "metadata": {
        "id": "sDj4d4E60qRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preventing disconnect from Google Colab notebook:\n",
        "Right-click on the connect button and paste the code to the console of the UI:\n",
        "\n",
        "\n",
        "```\n",
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\");\n",
        "    document.querySelector(\"colab-connect-button\").click() \n",
        " }\n",
        " setInterval(ClickConnect,60000)\n",
        "```"
      ],
      "metadata": {
        "id": "YyZY94ASp0yA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "AWqyY0_VS7jB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7ZBai_6xa0I",
        "outputId": "c644ad7c-2c1c-4537-85ee-4d89f0699d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.1.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.2.0\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==21.3.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "arviz==0.12.1\n",
            "astor==0.8.1\n",
            "astropy==4.3.1\n",
            "astunparse==1.6.3\n",
            "atari-py==0.2.9\n",
            "atomicwrites==1.4.0\n",
            "attrs==21.4.0\n",
            "audioread==2.1.9\n",
            "autograd==1.4\n",
            "Babel==2.10.2\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==5.0.0\n",
            "blis==0.7.7\n",
            "bokeh==2.3.3\n",
            "branca==0.5.0\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.11\n",
            "cached-property==1.5.2\n",
            "cachetools==4.2.4\n",
            "catalogue==2.0.7\n",
            "certifi==2022.6.15\n",
            "cffi==1.15.0\n",
            "cftime==1.6.0\n",
            "chardet==3.0.4\n",
            "charset-normalizer==2.0.12\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.22.5\n",
            "cmdstanpy==0.9.5\n",
            "colorcet==3.0.0\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.4.0\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda111==9.4.0\n",
            "cvxopt==1.2.7\n",
            "cvxpy==1.0.31\n",
            "cycler==0.11.0\n",
            "cymem==2.0.6\n",
            "Cython==0.29.30\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.5.1\n",
            "distributed==1.25.3\n",
            "dlib==19.18.0+zzzcolab20220513001918\n",
            "dm-tree==0.1.7\n",
            "docopt==0.6.2\n",
            "docutils==0.17.1\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.315\n",
            "easydict==1.9\n",
            "ecos==2.0.10\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl\n",
            "entrypoints==0.4\n",
            "ephem==4.1.3\n",
            "et-xmlfile==1.1.0\n",
            "fa2==0.3.5\n",
            "fastai==2.5.3\n",
            "fastcore==1.3.29\n",
            "fastdownload==0.0.6\n",
            "fastdtw==0.3.4\n",
            "fastjsonschema==2.15.3\n",
            "fastprogress==1.0.2\n",
            "fastrlock==0.8\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.7.1\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.4\n",
            "flatbuffers==2.0\n",
            "folium==0.8.3\n",
            "future==0.16.0\n",
            "gast==0.5.3\n",
            "GDAL==2.2.2\n",
            "gdown==4.4.0\n",
            "gensim==3.6.0\n",
            "geographiclib==1.52\n",
            "geopy==1.17.0\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.31.6\n",
            "google-api-python-client==1.12.11\n",
            "google-auth==1.35.0\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.6\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.2\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.56.2\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.1.2\n",
            "grpcio==1.46.3\n",
            "gspread==3.4.2\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.17.3\n",
            "h5py==3.1.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.2.4\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.14.9\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "imageio==2.4.1\n",
            "imagesize==1.3.0\n",
            "imbalanced-learn==0.8.1\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==4.11.4\n",
            "importlib-resources==5.7.1\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "intel-openmp==2022.1.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.7.0\n",
            "itsdangerous==1.1.0\n",
            "jax==0.3.8\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.7+cuda11.cudnn805-cp37-none-manylinux2014_x86_64.whl\n",
            "jedi==0.18.1\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "joblib==1.1.0\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==4.3.3\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.10.0\n",
            "jupyterlab-pygments==0.2.2\n",
            "jupyterlab-widgets==1.1.0\n",
            "kaggle==1.5.12\n",
            "kapre==0.3.7\n",
            "keras==2.8.0\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.4.3\n",
            "korean-lunar-calendar==0.2.1\n",
            "langcodes==3.3.0\n",
            "libclang==14.0.1\n",
            "librosa==0.8.1\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.7\n",
            "MarkupSafe==2.0.1\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.3\n",
            "matplotlib-venn==0.11.7\n",
            "missingno==0.5.1\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.13.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.4\n",
            "multiprocess==0.70.13\n",
            "multitasking==0.0.10\n",
            "murmurhash==1.0.7\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.6.4\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.4.0\n",
            "nest-asyncio==1.5.5\n",
            "netCDF4==1.5.8\n",
            "networkx==2.6.3\n",
            "nibabel==3.0.2\n",
            "nltk==3.7\n",
            "notebook==5.3.1\n",
            "numba==0.51.2\n",
            "numexpr==2.8.1\n",
            "numpy==1.21.6\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.0\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==3.0.10\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "packaging==21.3\n",
            "palettable==3.3.0\n",
            "pandas==1.3.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.5.0\n",
            "panel==0.12.1\n",
            "param==1.12.1\n",
            "parso==0.8.3\n",
            "pathlib==1.0.1\n",
            "pathy==0.6.1\n",
            "patsy==0.5.2\n",
            "pep517==0.12.0\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==6.2.0\n",
            "plotly==5.5.0\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.6.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.6\n",
            "prettytable==3.3.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.14.1\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.17.3\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.11.0\n",
            "pyarrow==6.0.1\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.4\n",
            "pycparser==2.21\n",
            "pyct==0.4.8\n",
            "pydantic==1.8.2\n",
            "pydata-google-auth==1.4.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==2.0.0.1\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.11.4\n",
            "PyMeeus==0.5.11\n",
            "pymongo==4.1.1\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.6\n",
            "pyparsing==3.0.9\n",
            "pyrsistent==0.18.1\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==6.1.2\n",
            "python-utils==3.3.3\n",
            "pytz==2022.1\n",
            "pyviz-comms==2.2.0\n",
            "PyWavelets==1.3.0\n",
            "PyYAML==3.13\n",
            "pyzmq==23.1.0\n",
            "qdldl==0.1.5.post2\n",
            "qtconsole==5.3.1\n",
            "QtPy==2.1.0\n",
            "regex==2022.6.2\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.1\n",
            "resampy==0.2.2\n",
            "rpy2==3.4.5\n",
            "rsa==4.8\n",
            "scikit-image==0.18.3\n",
            "scikit-learn==1.0.2\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==3.2.0\n",
            "seaborn==0.11.2\n",
            "semver==2.13.0\n",
            "Send2Trash==1.8.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.8.2\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.2.1\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "SoundFile==0.10.3.post1\n",
            "soupsieve==2.3.2.post1\n",
            "spacy==3.3.1\n",
            "spacy-legacy==3.0.9\n",
            "spacy-loggers==1.0.2\n",
            "Sphinx==1.8.6\n",
            "sphinxcontrib-serializinghtml==1.1.5\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.37\n",
            "sqlparse==0.4.2\n",
            "srsly==2.4.3\n",
            "statsmodels==0.10.2\n",
            "sympy==1.7.1\n",
            "tables==3.7.0\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tenacity==8.0.1\n",
            "tensorboard==2.8.0\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.1\n",
            "tensorflow==2.8.2+zzzcolab20220527125636\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.8.0\n",
            "tensorflow-gcs-config==2.8.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-io-gcs-filesystem==0.26.0\n",
            "tensorflow-metadata==1.8.0\n",
            "tensorflow-probability==0.16.0\n",
            "termcolor==1.1.0\n",
            "terminado==0.13.3\n",
            "testpath==0.6.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "Theano-PyMC==1.1.2\n",
            "thinc==8.0.17\n",
            "threadpoolctl==3.1.0\n",
            "tifffile==2021.11.2\n",
            "tinycss2==1.1.1\n",
            "tomli==2.0.1\n",
            "toolz==0.11.2\n",
            "torch==1.10.2\n",
            "torchaudio @ https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp37-cp37m-linux_x86_64.whl\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.12.0\n",
            "torchvision==0.11.3\n",
            "tornado==5.1.1\n",
            "tqdm==4.64.0\n",
            "traitlets==5.1.1\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typer==0.4.1\n",
            "typing-extensions==4.1.1\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.9.1\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.6.0\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.14.1\n",
            "xarray==0.20.2\n",
            "xarray-einstats==0.2.2\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==1.4\n",
            "zict==2.2.0\n",
            "zipp==3.8.0\n"
          ]
        }
      ],
      "source": [
        "%pip install fastai==2.5.3 -q\n",
        "%pip freeze"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from fastai.vision.all import *\n",
        "import sys"
      ],
      "metadata": {
        "id": "1JPm_NiTxqO9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vw-Wphv4xa0P"
      },
      "outputs": [],
      "source": [
        "# Load EB_ML python libraries\n",
        "# The following libraries are used in this notebook and should be installed in your local machine before running this notebook.\n",
        "# eb_colab_utils.py\n",
        "# eb_ml_battery_lib.py\n",
        "# eb_ml_utils.py\n",
        "\n",
        "# path to load external *.py files used in this notebook\n",
        "# Note: in Google Colab virtual machine you shoud copy the files in \"/content\" folder after BEFORE running this notebook's cell\n",
        "\n",
        "external_python_file_path=\"/content\"\n",
        "sys.path.append(external_python_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PKLZgvtOxa0Q"
      },
      "outputs": [],
      "source": [
        "from eb_ml_utils import build_data_loader,score_model\n",
        "from eb_ml_colab_utils import get_root_path\n",
        "from eb_ml_battery_lib import load_soc_dataset,generate_image_files_from_eis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment configuration "
      ],
      "metadata": {
        "id": "5FhF-7f5TLER"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfdsyJ5Uxa0R",
        "outputId": "9b342212-a512-479c-b7ae-6487562c8abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on COLAB\n",
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "#configuration dictionary\n",
        "config ={}\n",
        "\n",
        "# Root working folder (local or Google Drive)\n",
        "# config['ROOT_DIR'] = get_root_path(\"batterie\")\n",
        "config['ROOT_DIR'] = get_root_path(\"batterie\")  \n",
        "\n",
        "# Folder with dataset in CSV format\n",
        "#config['DATASETS_DIR'] = config['ROOT_DIR']+\"/datasets\"\n",
        "config['DATASETS_DIR'] = config['ROOT_DIR']+\"/datasets/EIS-vs-SOC-May2022\"\n",
        "\n",
        "# List of SoC level into dataset\n",
        "config['soc_list']=['100','090','080','070','060','050','040','030','020','010']\n",
        "\n",
        "# Folder to store trained model\n",
        "#config['MODELS_DIR'] = config['ROOT_DIR']+\"/models\"\n",
        "config['MODELS_DIR'] = config['ROOT_DIR']+\"/models\"\n",
        "\n",
        "#TODO: nel dataset di validazione alcune classi non sono rappresentate. Usare stratified splitter\n",
        "config['Splitter'] = RandomSplitter(valid_pct=0.3, seed=41)\n",
        "config['rePat'] = r'^.*_(\\d+).png$'\n",
        "\n",
        "\n",
        "#Acquisizioni dati caricare per inferenza con modello addestrato\n",
        "test_battery_list=[[6],[13],[14]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image file generation for inference"
      ],
      "metadata": {
        "id": "ARDHhyvLTjZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ywRkSH3Xxa0T"
      },
      "outputs": [],
      "source": [
        "# Enable/disable image dataset generation\n",
        "# Image generation process consume time and computational resources. \n",
        "# You need to generate image just once test EIS data acquisition\n",
        "# generate_images = False\n",
        "generate_images = False\n",
        "\n",
        "# List EIS data acquistion that need image generation\n",
        "#image_dataset_to_be_generated=[6,13,14]\n",
        "image_dataset_to_be_generated=['05_8']\n",
        "\n",
        "#GENERATE IMAGE\n",
        "if(generate_images):\n",
        "  for batt in image_dataset_to_be_generated:\n",
        "    config['ExperimentName']= \"BATTERY_\"+str(batt)\n",
        "    config['TEST_IMAGES_PATH']= config['ROOT_DIR']+\"/ForumMisure_TEST_DATA\"\n",
        "    test_dataset,feature_col_names=load_soc_dataset([batt],config[\"soc_list\"],config['DATASETS_DIR'])\n",
        "    generate_image_files_from_eis(test_dataset,feature_col_names,config['TEST_IMAGES_PATH'],config['ExperimentName'],DATA_AUGMENTATION_FACTOR=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Ensamble\n",
        "\n",
        "Inference with model ensamble on Test Data "
      ],
      "metadata": {
        "id": "tjv47-_a1CU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source data: battery EIS performed for SoC 100,90,80,70,60,50,40,30,20,10. Same frequnecies for each SoC\n",
        "\n",
        "Data format:  Re{Zbat}-Im{Zbat}j\n",
        "\n",
        "Data Acquisition:\n",
        "\n",
        "1. Batt1/Meas1\n",
        "2. Batt1/Meas2\n",
        "3. Batt2/Meas1 \n",
        "4. Batt2/Meas2\n",
        "5. Batt3/Meas1\n",
        "6. Batt3/Meas2 --> TEST\n",
        "7. Batt4/Meas1\n",
        "8. Batt5/Meas1\n",
        "9. Batt6/Meas1 \n",
        "10. Batt7/Meas1\n",
        "11. Batt8/Meas1\n",
        "12. Batt9/Meas1\n",
        "13. Batt10/Meas1 -->TEST\n",
        "14. Batt4/Meas2 -->TEST\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UWV-LqvaqKM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiments=['Paper_EIS_leave_one_out_02','Paper_EIS_leave_one_out_03','Paper_EIS_leave_one_out_05'] \n",
        "saved_weights_files= ['/gdrive/MyDrive/batterie/models/Paper_EIS_leave_one_out_02_1655745685.941974_SAVED',\n",
        "                      '/gdrive/MyDrive/batterie/models/Paper_EIS_leave_one_out_03_1655747010.611578_SAVED',\n",
        "                      '/gdrive/MyDrive/batterie/models/Paper_EIS_leave_one_out_05_1655748213.720466_SAVED'\n",
        "                      ]\n"
      ],
      "metadata": {
        "id": "jfojtJL41CCK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference on new data acquisition on battery 6"
      ],
      "metadata": {
        "id": "QqnaOgQWD-2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiments_predictions = []\n",
        "experiments_predictions_decoded=[]\n",
        "\n",
        "exeperiments_targets = []\n",
        "\n",
        "models_accuracy = []\n",
        "\n",
        "models_top2_accuracy = []\n",
        "\n",
        "config['TEST_IMAGES_PATH']= config['ROOT_DIR']+\"/ForumMisure_TEST_DATA/BATTERY_06_8/\"\n",
        "test_fnames= get_image_files(config[\"TEST_IMAGES_PATH\"])\n",
        "for experiment_index in range(0,len(experiments),1):\n",
        "  print(\"ExperimentName: \"+str(experiments[experiment_index]))\n",
        "  saved_weights=saved_weights_files[experiment_index]\n",
        "  config['ExperimentName'] = experiments[experiment_index]\n",
        "  config['IMAGES_PATH'] = config['ROOT_DIR']+\"/\"+config['ExperimentName']\n",
        "\n",
        "  # BUILD DATA LOADER\n",
        "  dl=build_data_loader(config)\n",
        "\n",
        "  # BUILD LEARNER\n",
        "  learn = cnn_learner(dl, resnet18, metrics=accuracy)\n",
        "\n",
        "  learn = learn.load(saved_weights)\n",
        "\n",
        "  # SCORE MODEL\n",
        "  #score_model(saved_weights,dl)\n",
        "\n",
        "  \n",
        "  test_dl = learn.dls.test_dl(test_fnames,with_labels=True)\n",
        "  predictions, targets, decoded = learn.get_preds(dl=test_dl, with_decoded=True)\n",
        "  experiments_predictions.append(predictions)\n",
        "  experiments_predictions_decoded.append(decoded)\n",
        "  exeperiments_targets.append(targets)\n",
        "  model_accuracy= accuracy(predictions,targets)\n",
        "  models_accuracy.append(model_accuracy)\n",
        "  from sklearn.metrics import top_k_accuracy_score\n",
        "  model_top2_accuracy= top_k_accuracy_score(targets, predictions, k=2)\n",
        "  models_top2_accuracy.append(model_top2_accuracy)\n",
        "  print(\"model_accuracy: \" + str(model_accuracy))\n",
        "  print(\"model_top2_accuracy: \" + str(model_top2_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "64ea888cba0b4fab8abe2f13f7a60ba4",
            "589c94566b8c49a380e63e1feeddbc33",
            "81cdf7fa3bf64ca79785dc3161e30760",
            "8fa6f54aa34c4d7297967adbf9a0e9d1",
            "2d9119e15dd340189f809d046e32a0e5",
            "ec858a3575d0420e95a9cd473fa13d51",
            "e7b200d6f58a4f5683b84286f46b92cd",
            "e5f080cb4ed848a38c9a1bea9df44e19",
            "5699fe0f4be243f9bc6c5dc7364d8027",
            "1beb291093894ffaa31b0b7ed1098f34",
            "eeaa2780ce76490d97f7ba422122aa04"
          ]
        },
        "outputId": "8f2fae73-4a87-4e8f-81ef-2ae65984c906",
        "id": "loNeEkIVEEhG"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExperimentName: Paper_EIS_leave_one_out_02\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_02\n",
            "Found 1040 items\n",
            "2 datasets of sizes 728,312\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_02/Paper_EIS_leave_one_out_02/EIS_BATT1835_050.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_02/Paper_EIS_leave_one_out_02/EIS_BATT1835_050.png\n",
            "    applying RegexLabeller gives\n",
            "      050\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(4)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(4))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_02\n",
            "Found 1040 items\n",
            "2 datasets of sizes 728,312\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(4))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(4))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(4))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([4, 9, 8, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([4, 9, 8, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([4, 9, 8, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64ea888cba0b4fab8abe2f13f7a60ba4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.6700)\n",
            "model_top2_accuracy: 0.93\n",
            "ExperimentName: Paper_EIS_leave_one_out_03\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_03\n",
            "Found 1040 items\n",
            "2 datasets of sizes 728,312\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_03/Paper_EIS_leave_one_out_03/EIS_BATT1835_050.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_03/Paper_EIS_leave_one_out_03/EIS_BATT1835_050.png\n",
            "    applying RegexLabeller gives\n",
            "      050\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(4)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(4))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_03\n",
            "Found 1040 items\n",
            "2 datasets of sizes 728,312\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(4))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(4))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(4))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([4, 9, 8, 0], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([4, 9, 8, 0], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([4, 9, 8, 0], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.5900)\n",
            "model_top2_accuracy: 0.81\n",
            "ExperimentName: Paper_EIS_leave_one_out_05\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_05\n",
            "Found 1100 items\n",
            "2 datasets of sizes 770,330\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_05/Paper_EIS_leave_one_out_05/EIS_BATT1173_070.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_05/Paper_EIS_leave_one_out_05/EIS_BATT1173_070.png\n",
            "    applying RegexLabeller gives\n",
            "      070\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(6)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(6))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_05\n",
            "Found 1100 items\n",
            "2 datasets of sizes 770,330\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(6))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(6))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(6))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([6, 1, 4, 7], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([6, 1, 4, 7], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([6, 1, 4, 7], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.6000)\n",
            "model_top2_accuracy: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5d9NFVzESqN",
        "outputId": "dd4a94e8-614a-4c77-9f77-e6ef8742d74e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TensorBase(0.6700), TensorBase(0.5900), TensorBase(0.6000)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(models_accuracy)"
      ],
      "metadata": {
        "id": "K-H_6hvgPcfZ",
        "outputId": "203d5a97-cef1-43f9-8baf-e7eb16b5dfef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.62"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_top2_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7O-RzXXEYLC",
        "outputId": "e0c23740-7f4b-4233-cf19-ae8509b71f71"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.93, 0.81, 0.83]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(models_top2_accuracy)"
      ],
      "metadata": {
        "id": "gBTqzv08PiUP",
        "outputId": "3b1587ba-ee5c-47eb-afaf-c56f1e21423f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8566666666666668"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate ensable prediction\n",
        "ensamble_prediction = experiments_predictions[0]\n",
        "for pred in experiments_predictions[1:]:\n",
        "  ensamble_prediction += pred\n",
        "\n",
        "ensamble_prediction /= len(experiments_predictions)\n",
        "#ensamble_accuracy\n",
        "accuracy(ensamble_prediction, exeperiments_targets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoA8r8lmEnaU",
        "outputId": "27a6f944-f2ae-484c-e634-6f602be25f82"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(0.6400)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference on new data acquisition on battery 5 (EIS Data acquisition 5_8: battery5 measurement 8)"
      ],
      "metadata": {
        "id": "vJrf6J3uXW77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiments_predictions = []\n",
        "\n",
        "exeperiments_targets = []\n",
        "\n",
        "models_accuracy = []\n",
        "\n",
        "models_top2_accuracy = []\n",
        "\n",
        "config['TEST_IMAGES_PATH']= config['ROOT_DIR']+\"/ForumMisure_TEST_DATA/BATTERY_05_8/\"\n",
        "test_fnames= get_image_files(config[\"TEST_IMAGES_PATH\"])\n",
        "for experiment_index in range(0,len(experiments),1):\n",
        "  print(\"ExperimentName: \"+str(experiments[experiment_index]))\n",
        "  saved_weights=saved_weights_files[experiment_index]\n",
        "  config['ExperimentName'] = experiments[experiment_index]\n",
        "  config['IMAGES_PATH'] = config['ROOT_DIR']+\"/\"+config['ExperimentName']\n",
        "\n",
        "  # BUILD DATA LOADER\n",
        "  dl=build_data_loader(config)\n",
        "\n",
        "  # BUILD LEARNER\n",
        "  learn = cnn_learner(dl, resnet18, metrics=accuracy)\n",
        "\n",
        "  learn = learn.load(saved_weights)\n",
        "\n",
        "  # SCORE MODEL\n",
        "  #score_model(saved_weights,dl)\n",
        "\n",
        "  \n",
        "  test_dl = learn.dls.test_dl(test_fnames,with_labels=True)\n",
        "  predictions, targets, decoded = learn.get_preds(dl=test_dl, with_decoded=True)\n",
        "  experiments_predictions.append(predictions)\n",
        "  exeperiments_targets.append(targets)\n",
        "  model_accuracy= accuracy(predictions,targets)\n",
        "  models_accuracy.append(model_accuracy)\n",
        "  from sklearn.metrics import top_k_accuracy_score\n",
        "  model_top2_accuracy= top_k_accuracy_score(targets, predictions, k=2)\n",
        "  models_top2_accuracy.append(model_top2_accuracy)\n",
        "  print(\"model_accuracy: \" + str(model_accuracy))\n",
        "  print(\"model_top2_accuracy: \" + str(model_top2_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e086a3a7-ddab-40e3-c481-5218cdced9ad",
        "id": "rwsfCV01XUFb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExperimentName: Paper_EIS_leave_one_out_02\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_02\n",
            "Found 1040 items\n",
            "2 datasets of sizes 728,312\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_02/Paper_EIS_leave_one_out_02/EIS_BATT1835_050.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_02/Paper_EIS_leave_one_out_02/EIS_BATT1835_050.png\n",
            "    applying RegexLabeller gives\n",
            "      050\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(4)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(4))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_02\n",
            "Found 1040 items\n",
            "2 datasets of sizes 728,312\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(4))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(4))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(4))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([4, 9, 8, 9], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([4, 9, 8, 9], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([4, 9, 8, 9], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(1.)\n",
            "model_top2_accuracy: 1.0\n",
            "ExperimentName: Paper_EIS_leave_one_out_03\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_03\n",
            "Found 1040 items\n",
            "2 datasets of sizes 728,312\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_03/Paper_EIS_leave_one_out_03/EIS_BATT1835_050.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_03/Paper_EIS_leave_one_out_03/EIS_BATT1835_050.png\n",
            "    applying RegexLabeller gives\n",
            "      050\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(4)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(4))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_03\n",
            "Found 1040 items\n",
            "2 datasets of sizes 728,312\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(4))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(4))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(4))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([4, 9, 8, 0], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([4, 9, 8, 0], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([4, 9, 8, 0], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(1.)\n",
            "model_top2_accuracy: 1.0\n",
            "ExperimentName: Paper_EIS_leave_one_out_05\n",
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_05\n",
            "Found 1100 items\n",
            "2 datasets of sizes 770,330\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_05/Paper_EIS_leave_one_out_05/EIS_BATT1173_070.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_05/Paper_EIS_leave_one_out_05/EIS_BATT1173_070.png\n",
            "    applying RegexLabeller gives\n",
            "      070\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(6)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(6))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_leave_one_out_05\n",
            "Found 1100 items\n",
            "2 datasets of sizes 770,330\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(6))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(6))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(6))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([6, 1, 4, 7], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([6, 1, 4, 7], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([6, 1, 4, 7], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(1.)\n",
            "model_top2_accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_accuracy"
      ],
      "metadata": {
        "id": "XUgcPINxYffl",
        "outputId": "f64000b7-f046-45cd-a7f6-d788319a4e95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TensorBase(1.), TensorBase(1.), TensorBase(1.)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(models_accuracy)"
      ],
      "metadata": {
        "id": "misOYS08PwSF",
        "outputId": "6fce6c51-da95-485d-f3f5-3cc3352b7d8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_top2_accuracy"
      ],
      "metadata": {
        "id": "yWxfnQK0Yffm",
        "outputId": "580cb6c1-7c7a-41d6-c245-e25bf862fa17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 1.0, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(models_top2_accuracy)"
      ],
      "metadata": {
        "id": "ZnxaFKbJP25A",
        "outputId": "42a5cf8f-b623-44f3-c838-21f7493428f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate ensable prediction\n",
        "ensamble_prediction = experiments_predictions[0]\n",
        "for pred in experiments_predictions[1:]:\n",
        "  ensamble_prediction += pred\n",
        "\n",
        "ensamble_prediction /= len(experiments_predictions)\n",
        "#ensamble_accuracy\n",
        "accuracy(ensamble_prediction, exeperiments_targets[0])"
      ],
      "metadata": {
        "id": "Su_0Dcj6Yffm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7adbe42-41f1-4040-b0ef-e6f004398fd4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ensamble top2 accuracy\n",
        "top_k_accuracy_score(exeperiments_targets[0], ensamble_prediction, k=2)"
      ],
      "metadata": {
        "id": "dC54B2UmYffm",
        "outputId": "fe7f0b66-18b9-4943-aebb-5ee05bb6a9f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Model - Training/Validation split\n",
        "\n",
        "Modello addestrato con tutti i dati tranne batteria 3 e 10"
      ],
      "metadata": {
        "id": "o1aZkmU9QZb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model trained on data acquisition from batteries 1,2,4,5,6,7,8,9\n",
        "# acquistion from batteries 3 and 10 used only for inference test\n",
        "saved_weights = \"/gdrive/MyDrive/batterie/models/Paper_EIS_single_model_BATT-2-3-5_1655745145.09554_SAVED\"\n",
        "\n",
        "config['ExperimentName'] = \"Paper_EIS_single_model_BATT-2-3-5\"\n",
        "config['IMAGES_PATH'] = config['ROOT_DIR']+\"/\"+config['ExperimentName']"
      ],
      "metadata": {
        "id": "cflLfcHwydMb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test on new data acquisition on battery 5 (measurement 8)"
      ],
      "metadata": {
        "id": "jUEfs9KOjdfI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f6567d6-b169-42ca-f9f7-7d6a3bc38979",
        "id": "fWlqwVTljiMP"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_single_model_BATT-2-3-5\n",
            "Found 1140 items\n",
            "2 datasets of sizes 798,342\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_single_model_BATT-2-3-5/Paper_EIS_single_model_BATT-2-3-5/EIS_BATT1988_020.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_single_model_BATT-2-3-5/Paper_EIS_single_model_BATT-2-3-5/EIS_BATT1988_020.png\n",
            "    applying RegexLabeller gives\n",
            "      020\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(1)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(1))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_single_model_BATT-2-3-5\n",
            "Found 1140 items\n",
            "2 datasets of sizes 798,342\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(1))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(1))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(1))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([1, 2, 3, 8], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([1, 2, 3, 8], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([1, 2, 3, 8], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.9000)\n",
            "model_top2_accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "config['TEST_IMAGES_PATH']= config['ROOT_DIR']+\"/ForumMisure_TEST_DATA/BATTERY_05_8/\"\n",
        "test_fnames= get_image_files(config[\"TEST_IMAGES_PATH\"])\n",
        "#DATA LOADER\n",
        "dl=build_data_loader(config)\n",
        "\n",
        "# BUILD LEARNER\n",
        "learn = cnn_learner(dl, resnet18, metrics=accuracy)\n",
        "\n",
        "learn = learn.load(saved_weights)\n",
        "\n",
        "test_dl = learn.dls.test_dl(test_fnames,with_labels=True)\n",
        "predictions, targets, decoded = learn.get_preds(dl=test_dl, with_decoded=True)\n",
        "model_accuracy= accuracy(predictions,targets)\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "model_top2_accuracy= top_k_accuracy_score(targets, predictions, k=2)\n",
        "print(\"model_accuracy: \" + str(model_accuracy))\n",
        "print(\"model_top2_accuracy: \" + str(model_top2_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SCORE MODEL\n",
        "score_model(saved_weights,dl)"
      ],
      "metadata": {
        "id": "4OziE4PGjyiX",
        "outputId": "861d9d00-3124-4f86-c96a-3f2315b34ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[42  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 39  2  0  0  0  0  0  0  0]\n",
            " [ 0  1 25  3  1  0  0  0  0  0]\n",
            " [ 0  0  2 20  0  0  0  0  0  0]\n",
            " [ 0  0  0  3 31  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 35  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 41  2  0  0]\n",
            " [ 0  0  0  0  0  0  3 28  0  0]\n",
            " [ 0  0  0  0  0  0  0  2 27  0]\n",
            " [ 0  0  4  0  0  0  0  0  0 31]]\n",
            "[[1.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.95121951 0.04878049 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.03333333 0.83333333 0.1        0.03333333 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.09090909 0.90909091 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.08823529 0.91176471 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.95348837 0.04651163 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.09677419 0.90322581 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.06896552 0.93103448 0.        ]\n",
            " [0.         0.         0.11428571 0.         0.         0.\n",
            "  0.         0.         0.         0.88571429]]\n",
            "interpretation.most_confused()\n",
            "interpretation.top_losses()\n",
            "interpretation.print_classification_report()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         010       1.00      1.00      1.00        42\n",
            "         020       0.97      0.95      0.96        41\n",
            "         030       0.76      0.83      0.79        30\n",
            "         040       0.77      0.91      0.83        22\n",
            "         050       0.97      0.91      0.94        34\n",
            "         060       1.00      1.00      1.00        35\n",
            "         070       0.93      0.95      0.94        43\n",
            "         080       0.88      0.90      0.89        31\n",
            "         090       1.00      0.93      0.96        29\n",
            "         100       1.00      0.89      0.94        35\n",
            "\n",
            "    accuracy                           0.93       342\n",
            "   macro avg       0.93      0.93      0.93       342\n",
            "weighted avg       0.94      0.93      0.93       342\n",
            "\n",
            "learn.show_results()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learn.validate()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 0.93\n",
            "learn.get_preds()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(0.9327)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test on new battery (battery 6)"
      ],
      "metadata": {
        "id": "D6khANrejTYF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XFZ1w6t7xa0T",
        "outputId": "846e9763-4ec8-4679-a29e-170da799d896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_single_model_BATT-2-3-5\n",
            "Found 1140 items\n",
            "2 datasets of sizes 798,342\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_single_model_BATT-2-3-5/Paper_EIS_single_model_BATT-2-3-5/EIS_BATT1988_020.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=432x288\n",
            "  Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "    starting from\n",
            "      /gdrive/MyDrive/batterie/Paper_EIS_single_model_BATT-2-3-5/Paper_EIS_single_model_BATT-2-3-5/EIS_BATT1988_020.png\n",
            "    applying RegexLabeller gives\n",
            "      020\n",
            "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
            "      TensorCategory(1)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=432x288, TensorCategory(1))\n",
            "\n",
            "\n",
            "Collecting items from /gdrive/MyDrive/batterie/Paper_EIS_single_model_BATT-2-3-5\n",
            "Found 1140 items\n",
            "2 datasets of sizes 798,342\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: RegexLabeller -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
            "Setting up after_item: Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=432x288, TensorCategory(1))\n",
            "    applying Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
            "      (PILImage mode=RGB size=224x224, TensorCategory(1))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x224x224, TensorCategory(1))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([1, 2, 3, 8], device='cuda:0'))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([1, 2, 3, 8], device='cuda:0'))\n",
            "    applying Normalize -- {'mean': tensor([[[[0.4850]],\n",
            "\n",
            "         [[0.4560]],\n",
            "\n",
            "         [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
            "\n",
            "         [[0.2240]],\n",
            "\n",
            "         [[0.2250]]]], device='cuda:0'), 'axes': (0, 2, 3)} gives\n",
            "      (TensorImage of size 4x3x224x224, TensorCategory([1, 2, 3, 8], device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_accuracy: TensorBase(0.6800)\n",
            "model_top2_accuracy: 0.87\n"
          ]
        }
      ],
      "source": [
        "config['TEST_IMAGES_PATH']= config['ROOT_DIR']+\"/ForumMisure_TEST_DATA/BATTERY_06_6/\"\n",
        "test_fnames= get_image_files(config[\"TEST_IMAGES_PATH\"])\n",
        "#DATA LOADER\n",
        "dl=build_data_loader(config)\n",
        "\n",
        "# BUILD LEARNER\n",
        "learn = cnn_learner(dl, resnet18, metrics=accuracy)\n",
        "\n",
        "learn = learn.load(saved_weights)\n",
        "\n",
        "test_dl = learn.dls.test_dl(test_fnames,with_labels=True)\n",
        "predictions, targets, decoded = learn.get_preds(dl=test_dl, with_decoded=True)\n",
        "model_accuracy= accuracy(predictions,targets)\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "model_top2_accuracy= top_k_accuracy_score(targets, predictions, k=2)\n",
        "print(\"model_accuracy: \" + str(model_accuracy))\n",
        "print(\"model_top2_accuracy: \" + str(model_top2_accuracy))"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Paper_EIS_inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "64ea888cba0b4fab8abe2f13f7a60ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_589c94566b8c49a380e63e1feeddbc33",
              "IPY_MODEL_81cdf7fa3bf64ca79785dc3161e30760",
              "IPY_MODEL_8fa6f54aa34c4d7297967adbf9a0e9d1"
            ],
            "layout": "IPY_MODEL_2d9119e15dd340189f809d046e32a0e5"
          }
        },
        "589c94566b8c49a380e63e1feeddbc33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec858a3575d0420e95a9cd473fa13d51",
            "placeholder": "​",
            "style": "IPY_MODEL_e7b200d6f58a4f5683b84286f46b92cd",
            "value": "100%"
          }
        },
        "81cdf7fa3bf64ca79785dc3161e30760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5f080cb4ed848a38c9a1bea9df44e19",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5699fe0f4be243f9bc6c5dc7364d8027",
            "value": 46830571
          }
        },
        "8fa6f54aa34c4d7297967adbf9a0e9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1beb291093894ffaa31b0b7ed1098f34",
            "placeholder": "​",
            "style": "IPY_MODEL_eeaa2780ce76490d97f7ba422122aa04",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 63.0MB/s]"
          }
        },
        "2d9119e15dd340189f809d046e32a0e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec858a3575d0420e95a9cd473fa13d51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7b200d6f58a4f5683b84286f46b92cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5f080cb4ed848a38c9a1bea9df44e19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5699fe0f4be243f9bc6c5dc7364d8027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1beb291093894ffaa31b0b7ed1098f34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeaa2780ce76490d97f7ba422122aa04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}